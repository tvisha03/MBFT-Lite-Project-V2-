{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1843149a-436e-4d31-9db3-e70825c8edb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ Working directory set to: /Users/tvishakhanna/MBFT_LITE_FL/fl_metadata\n"
     ]
    }
   ],
   "source": [
    "# ðŸ““ 07_fl_metadata_simulation.ipynb\n",
    "\n",
    "import subprocess\n",
    "import time\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Set working directory to fl_metadata\n",
    "FL_DIR = Path(\"../fl_metadata\").resolve()\n",
    "print(f\"ðŸ’¡ Working directory set to: {FL_DIR}\")\n",
    "\n",
    "# Number of clients to simulate\n",
    "NUM_CLIENTS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "475739c5-ccea-4317-b14b-6a41e5afba72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸš€ Starting Federated Server...\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Start the Flower server\n",
    "print(\"\\nðŸš€ Starting Federated Server...\")\n",
    "server_proc = subprocess.Popen(\n",
    "    [\"python3\", \"server.py\"],\n",
    "    cwd=FL_DIR,\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.STDOUT,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "# Allow server to start up\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1f9baa0-c133-4f27-8b2e-a1c20af20c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ‘¥ Launching FL Clients...\n",
      "âœ… Client 1 started.\n",
      "âœ… Client 2 started.\n",
      "âœ… Client 3 started.\n",
      "âœ… Client 4 started.\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Start FL clients (each in its own subprocess)\n",
    "client_procs = []\n",
    "print(\"\\nðŸ‘¥ Launching FL Clients...\")\n",
    "for client_id in range(1, NUM_CLIENTS + 1):\n",
    "    env = os.environ.copy()\n",
    "    env[\"CLIENT_ID\"] = str(client_id)\n",
    "    proc = subprocess.Popen(\n",
    "        [\"python3\", \"client.py\"],\n",
    "        cwd=FL_DIR,\n",
    "        env=env,\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.STDOUT,\n",
    "        text=True\n",
    "    )\n",
    "    client_procs.append(proc)\n",
    "    print(f\"âœ… Client {client_id} started.\")\n",
    "    time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62d6dd7-2f65-4aff-903b-944e618abf32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“¡ Server Output:\n",
      "INFO flwr 2025-04-04 19:52:59,299 | app.py:139 | Starting Flower server, config: ServerConfig(num_rounds=5, round_timeout=None)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1743776579.304452 1175850 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "INFO flwr 2025-04-04 19:52:59,308 | app.py:152 | Flower ECE: gRPC server running (5 rounds), SSL is disabled\n",
      "INFO flwr 2025-04-04 19:52:59,308 | server.py:86 | Initializing global parameters\n",
      "INFO flwr 2025-04-04 19:52:59,308 | server.py:270 | Requesting initial parameters from one random client\n",
      "I0000 00:00:1743776579.311377 1175850 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "I0000 00:00:1743776579.315594 1175850 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "INFO flwr 2025-04-04 19:53:03,418 | server.py:274 | Received initial parameters from one random client\n",
      "INFO flwr 2025-04-04 19:53:03,418 | server.py:88 | Evaluating initial parameters\n",
      "INFO flwr 2025-04-04 19:53:03,418 | server.py:101 | FL starting\n",
      "DEBUG flwr 2025-04-04 19:53:04,106 | server.py:215 | fit_round 1: strategy sampled 2 clients (out of 2)\n",
      "DEBUG flwr 2025-04-04 19:53:04,141 | server.py:229 | fit_round 1 received 2 results and 0 failures\n",
      "ðŸš€ Federated XGBoost Server starting...\n",
      "Traceback (most recent call last):\n",
      "File \"/Users/tvishakhanna/MBFT_LITE_FL/fl_metadata/server.py\", line 15, in <module>\n",
      "fl.server.start_server(\n",
      "File \"/opt/anaconda3/envs/mbft_lite_env/lib/python3.10/site-packages/flwr/server/app.py\", line 160, in start_server\n",
      "hist = _fl(\n",
      "File \"/opt/anaconda3/envs/mbft_lite_env/lib/python3.10/site-packages/flwr/server/app.py\", line 201, in _fl\n",
      "hist = server.fit(num_rounds=config.num_rounds, timeout=config.round_timeout)\n",
      "File \"/opt/anaconda3/envs/mbft_lite_env/lib/python3.10/site-packages/flwr/server/server.py\", line 106, in fit\n",
      "res_fit = self.fit_round(server_round=current_round, timeout=timeout)\n",
      "File \"/opt/anaconda3/envs/mbft_lite_env/lib/python3.10/site-packages/flwr/server/server.py\", line 241, in fit_round\n",
      "] = self.strategy.aggregate_fit(server_round, results, failures)\n",
      "File \"/opt/anaconda3/envs/mbft_lite_env/lib/python3.10/site-packages/flwr/server/strategy/fedavg.py\", line 234, in aggregate_fit\n",
      "parameters_aggregated = ndarrays_to_parameters(aggregate(weights_results))\n",
      "File \"/opt/anaconda3/envs/mbft_lite_env/lib/python3.10/site-packages/flwr/server/strategy/aggregate.py\", line 37, in aggregate\n",
      "weights_prime: NDArrays = [\n",
      "File \"/opt/anaconda3/envs/mbft_lite_env/lib/python3.10/site-packages/flwr/server/strategy/aggregate.py\", line 38, in <listcomp>\n",
      "reduce(np.add, layer_updates) / num_examples_total\n",
      "ValueError: operands could not be broadcast together with shapes (16329,) (18702,)\n",
      "Exception in thread Thread-1 (_serve):\n",
      "Traceback (most recent call last):\n",
      "File \"/opt/anaconda3/envs/mbft_lite_env/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "self.run()\n",
      "File \"/opt/anaconda3/envs/mbft_lite_env/lib/python3.10/threading.py\", line 953, in run\n",
      "self._target(*self._args, **self._kwargs)\n",
      "File \"/opt/anaconda3/envs/mbft_lite_env/lib/python3.10/site-packages/grpc/_server.py\", line 1334, in _serve\n",
      "if not _process_event_and_continue(state, event):\n",
      "File \"/opt/anaconda3/envs/mbft_lite_env/lib/python3.10/site-packages/grpc/_server.py\", line 1288, in _process_event_and_continue\n",
      "rpc_state, rpc_future = _handle_call(\n",
      "File \"/opt/anaconda3/envs/mbft_lite_env/lib/python3.10/site-packages/grpc/_server.py\", line 1127, in _handle_call\n",
      "_handle_with_method_handler(\n",
      "File \"/opt/anaconda3/envs/mbft_lite_env/lib/python3.10/site-packages/grpc/_server.py\", line 1051, in _handle_with_method_handler\n",
      "return _handle_stream_stream(\n",
      "File \"/opt/anaconda3/envs/mbft_lite_env/lib/python3.10/site-packages/grpc/_server.py\", line 975, in _handle_stream_stream\n",
      "return thread_pool.submit(\n",
      "File \"/opt/anaconda3/envs/mbft_lite_env/lib/python3.10/concurrent/futures/thread.py\", line 169, in submit\n",
      "raise RuntimeError('cannot schedule new futures after '\n",
      "RuntimeError: cannot schedule new futures after interpreter shutdown\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Stream server logs\n",
    "print(\"\\nðŸ“¡ Server Output:\")\n",
    "try:\n",
    "    while True:\n",
    "        line = server_proc.stdout.readline()\n",
    "        if not line:\n",
    "            break\n",
    "        print(line.strip())\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nðŸ›‘ FL simulation interrupted by user.\")\n",
    "\n",
    "# Optional: Wait for all client processes to finish\n",
    "for proc in client_procs:\n",
    "    proc.wait()\n",
    "\n",
    "print(\"\\nâœ… Federated Learning simulation complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2e4626-18ed-4603-982e-2fb2f4668ec6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
