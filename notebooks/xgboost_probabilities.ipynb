{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "912b8fc1-2fa9-4517-9a87-1212c80f1ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-logloss:0.61324\n",
      "[1]\teval-logloss:0.54795\n",
      "[2]\teval-logloss:0.49365\n",
      "[3]\teval-logloss:0.44780\n",
      "[4]\teval-logloss:0.40759\n",
      "[5]\teval-logloss:0.37434\n",
      "[6]\teval-logloss:0.34556\n",
      "[7]\teval-logloss:0.31849\n",
      "[8]\teval-logloss:0.29541\n",
      "[9]\teval-logloss:0.27538\n",
      "[10]\teval-logloss:0.25732\n",
      "[11]\teval-logloss:0.24160\n",
      "[12]\teval-logloss:0.22767\n",
      "[13]\teval-logloss:0.21417\n",
      "[14]\teval-logloss:0.20361\n",
      "[15]\teval-logloss:0.19339\n",
      "[16]\teval-logloss:0.18279\n",
      "[17]\teval-logloss:0.17580\n",
      "[18]\teval-logloss:0.16789\n",
      "[19]\teval-logloss:0.16096\n",
      "[20]\teval-logloss:0.15539\n",
      "[21]\teval-logloss:0.15066\n",
      "[22]\teval-logloss:0.14547\n",
      "[23]\teval-logloss:0.14094\n",
      "[24]\teval-logloss:0.13777\n",
      "[25]\teval-logloss:0.13430\n",
      "[26]\teval-logloss:0.13033\n",
      "[27]\teval-logloss:0.12674\n",
      "[28]\teval-logloss:0.12513\n",
      "[29]\teval-logloss:0.12206\n",
      "[30]\teval-logloss:0.11988\n",
      "[31]\teval-logloss:0.11800\n",
      "[32]\teval-logloss:0.11565\n",
      "[33]\teval-logloss:0.11484\n",
      "[34]\teval-logloss:0.11311\n",
      "[35]\teval-logloss:0.11081\n",
      "[36]\teval-logloss:0.10940\n",
      "[37]\teval-logloss:0.10744\n",
      "[38]\teval-logloss:0.10655\n",
      "[39]\teval-logloss:0.10457\n",
      "[40]\teval-logloss:0.10272\n",
      "[41]\teval-logloss:0.10135\n",
      "[42]\teval-logloss:0.10066\n",
      "[43]\teval-logloss:0.09977\n",
      "[44]\teval-logloss:0.09923\n",
      "[45]\teval-logloss:0.09826\n",
      "[46]\teval-logloss:0.09802\n",
      "[47]\teval-logloss:0.09771\n",
      "[48]\teval-logloss:0.09726\n",
      "[49]\teval-logloss:0.09734\n",
      "[50]\teval-logloss:0.09747\n",
      "[51]\teval-logloss:0.09654\n",
      "[52]\teval-logloss:0.09664\n",
      "[53]\teval-logloss:0.09708\n",
      "[54]\teval-logloss:0.09726\n",
      "[55]\teval-logloss:0.09632\n",
      "[56]\teval-logloss:0.09654\n",
      "[57]\teval-logloss:0.09559\n",
      "[58]\teval-logloss:0.09508\n",
      "[59]\teval-logloss:0.09469\n",
      "[60]\teval-logloss:0.09356\n",
      "[61]\teval-logloss:0.09297\n",
      "[62]\teval-logloss:0.09269\n",
      "[63]\teval-logloss:0.09219\n",
      "[64]\teval-logloss:0.09221\n",
      "[65]\teval-logloss:0.09136\n",
      "[66]\teval-logloss:0.09074\n",
      "[67]\teval-logloss:0.09061\n",
      "[68]\teval-logloss:0.09009\n",
      "[69]\teval-logloss:0.08956\n",
      "[70]\teval-logloss:0.08925\n",
      "[71]\teval-logloss:0.08934\n",
      "[72]\teval-logloss:0.08864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/mbft_lite_env/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:48:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[73]\teval-logloss:0.08833\n",
      "[74]\teval-logloss:0.08802\n",
      "[75]\teval-logloss:0.08809\n",
      "[76]\teval-logloss:0.08762\n",
      "[77]\teval-logloss:0.08788\n",
      "[78]\teval-logloss:0.08777\n",
      "[79]\teval-logloss:0.08714\n",
      "[80]\teval-logloss:0.08700\n",
      "[81]\teval-logloss:0.08655\n",
      "[82]\teval-logloss:0.08651\n",
      "[83]\teval-logloss:0.08661\n",
      "[84]\teval-logloss:0.08645\n",
      "[85]\teval-logloss:0.08609\n",
      "[86]\teval-logloss:0.08535\n",
      "[87]\teval-logloss:0.08553\n",
      "[88]\teval-logloss:0.08544\n",
      "[89]\teval-logloss:0.08527\n",
      "[90]\teval-logloss:0.08552\n",
      "[91]\teval-logloss:0.08534\n",
      "[92]\teval-logloss:0.08554\n",
      "[93]\teval-logloss:0.08559\n",
      "[94]\teval-logloss:0.08548\n",
      "[95]\teval-logloss:0.08538\n",
      "[96]\teval-logloss:0.08503\n",
      "[97]\teval-logloss:0.08461\n",
      "[98]\teval-logloss:0.08471\n",
      "[99]\teval-logloss:0.08426\n",
      "Predicted probabilities (first 5 samples): [0.97605604 0.42612672 0.9972556  0.00110426 0.00177454]\n",
      "Validation Accuracy: 0.9670658682634731\n",
      "Validation Log Loss: 0.08425596146906676\n",
      "✅ XGBoost probabilities saved to ../data/unseen/xgboost_probabilities.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "# Load the cleaned tokenized dataset with all 23 features\n",
    "df_cleaned = pd.read_csv('../data/unseen/client_ceas_unseen_cleaned.csv')\n",
    "\n",
    "# List of features (23 features based on what was saved before)\n",
    "features = [\n",
    "    'sender_domain_length', 'sender_has_digits', 'sender_has_special_chars', \n",
    "    'sender_tld', 'sender_is_public_domain', 'receiver_is_undisclosed', \n",
    "    'receiver_is_public_domain', 'sender_equals_receiver', 'email_hour', \n",
    "    'is_weekend', 'url_present', 'url_has_ip', 'url_has_special_chars', \n",
    "    'url_has_redirect', 'url_suspicious_tld', 'subject_length', 'body_length', \n",
    "    'text_combined_length', 'uppercase_ratio', 'exclamation_count', 'label', \n",
    "    'url_length_ratio', 'url_density'\n",
    "]\n",
    "\n",
    "# The 'label' column is the target variable (class to predict)\n",
    "X = df_cleaned[features].drop(columns=['label'])  # Features\n",
    "y = df_cleaned['label']  # Target variable (labels)\n",
    "\n",
    "# Split the dataset into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to DMatrix for XGBoost (the optimized data structure for XGBoost)\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dval = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "# Define the XGBoost model parameters\n",
    "params = {\n",
    "    \"objective\": \"binary:logistic\",  # Binary classification\n",
    "    \"eval_metric\": \"logloss\",        # Use logloss as the evaluation metric\n",
    "    \"max_depth\": 6,                  # Maximum depth of a tree\n",
    "    \"learning_rate\": 0.1,            # Step size shrinkage\n",
    "    \"n_estimators\": 100,             # Number of trees (boosting rounds)\n",
    "}\n",
    "\n",
    "# Train the XGBoost model\n",
    "bst = xgb.train(params, dtrain, num_boost_round=100, evals=[(dval, 'eval')])\n",
    "\n",
    "# Get predicted probabilities (probability of class 1)\n",
    "y_pred_prob = bst.predict(dval)\n",
    "\n",
    "# Print the first few predicted probabilities\n",
    "print(\"Predicted probabilities (first 5 samples):\", y_pred_prob[:5])\n",
    "\n",
    "# Calculate accuracy and logloss\n",
    "y_pred_class = (y_pred_prob > 0.5).astype(int)  # Convert probabilities to class labels\n",
    "accuracy = accuracy_score(y_val, y_pred_class)\n",
    "logloss = log_loss(y_val, y_pred_prob)\n",
    "\n",
    "print(f\"Validation Accuracy: {accuracy}\")\n",
    "print(f\"Validation Log Loss: {logloss}\")\n",
    "\n",
    "# Save the predicted probabilities\n",
    "probabilities_df = pd.DataFrame({\n",
    "    'prob_class_0': 1 - y_pred_prob,  # Probabilities for class 0\n",
    "    'prob_class_1': y_pred_prob,      # Probabilities for class 1\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "probabilities_save_path = \"../data/unseen/xgboost_probabilities.csv\"\n",
    "probabilities_df.to_csv(probabilities_save_path, index=False)\n",
    "\n",
    "print(f\"✅ XGBoost probabilities saved to {probabilities_save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f442d1-7448-4928-b45b-72272dbf0edc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
